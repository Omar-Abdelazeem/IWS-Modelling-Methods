{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting a Normal EPANET .inp File to a CV-Res IWS File [1]\n",
    "This notebook takes an input EPANET files with demands input normally as a CWS base demand and adds the necessary elements to convert it into a CV-Res IWS simulation  \n",
    "For details on the CV-Res method refer to [1]  \n",
    "A simplified schematic of the modified demand node in STM is seen below:  \n",
    "  \n",
    "  \n",
    "![](CV-Res.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, we import the necessary libraries and packages\n",
    "**WNTR** for building EPANET network models in Python  \n",
    "**NUMPY & PANDAS** for data handling and processing  \n",
    "**re** for searching and matching text in the .inp file using regular expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wntr  \n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import re\n",
    "import pathlib"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specifying paths for simulation files and preprocessing the input\n",
    "**Warning:** *Paths in this script (and the rest of this repo) are absolute unless running the network files provided within the repo*  \n",
    "Input filename (with extensions) as string.  \n",
    "For running the .inp files in this repository, you can use this relative path `\"../Network-Files/Network X/\"` where X is the network number "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected File:  Gupta_and_Bhave_12hr\n"
     ]
    }
   ],
   "source": [
    " # Replace with appropriate path and filename\n",
    "directory=pathlib.Path(\"../Network-Files/Network 1\")\n",
    "filename=pathlib.Path(\"Network1_12hr_PDA.inp\")\n",
    "name_only=str(filename.stem)[0:-4]\n",
    "print(\"Selected File: \",name_only)\n",
    "path=directory/filename"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Necessary Assumptions Input\n",
    "Converting a CWS demand-driven analysis into an IWS pressure-driven analysis requires some assumptions in all methods  \n",
    "The resistance of the service connection between the demand node and the household (end-user) is uncertain and is modelled using two assumptions  \n",
    "The **desired head (pressure)** is the pressure at the demand node at which (or above) the consumer can satisfy their full demand in the supply duration (or possible less)  \n",
    "The **minimum head (pressure)** is the minimum pressure at the demand node required for flow to begin passing through the service connection  \n",
    "These two assumptions dictate the flow-pressure relationship that determines the pressure-dependent flow through the service connection as follows:\n",
    "\n",
    "$$ Q\\, = \\!Q_{des}\\sqrt{\\frac{H_{j}-H^{min}}{H^{des}-H^{min}}} \\quad[2]$$ \n",
    "Where Q is the flow through the service connection, $Q_{des}$ is the desired (base) demand, $H_j$ is the head at the demand node $j$, $H^{min}$ is the minimum head, and $H^{des}$ is the desired head\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_pressure=10     # Set the desired pressure\n",
    "minimum_pressure=0      # Set the minimum pressure\n",
    "pressure_diff=desired_pressure-minimum_pressure  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting information from the input file\n",
    "To modify the .inp file, demand node IDs, elevations, x and y coordinates  \n",
    "We use wntr to build the network model of the input file and use wntr's junctions module to extract the details of each node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "demand_nodes=[]       # For storing list of nodes that have non-zero demands\n",
    "desired_demands=[]    # For storing demand rates desired by each node for desired volume calculations\n",
    "elevations=[]         # For storing elevations of demand nodes\n",
    "xcoordinates=[]       # For storing x coordinates of demand nodes\n",
    "ycoordinates=[]       # For storing y coordinates of demand nodes\n",
    "all_nodes=[]          # For storing list of node ids of all nodes\n",
    "all_elevations=[]     # For storing elevations of all nodes\n",
    "## MAYBE SAVE ALL NODE IDS IN DATAFRAME WITH ELEVATION AND BASE DEMAND AND THEN FILTER DATA FRAME LATER FOR DEMAND NODES ONLY\n",
    "\n",
    "# Creates a network model object using EPANET .inp file\n",
    "network=wntr.network.WaterNetworkModel(path)\n",
    "\n",
    "# Iterates over the junction list in the Network object\n",
    "for node in network.junctions():\n",
    "    all_nodes.append(node[1].name)\n",
    "    all_elevations.append(node[1].elevation)\n",
    "    # For all nodes that have non-zero demands\n",
    "    if node[1].base_demand != 0:\n",
    "        # Record node ID (name), desired demand (base_demand) in CMS, elevations, x and y coordinates\n",
    "        demand_nodes.append(node[1].name)\n",
    "        desired_demands.append(node[1].base_demand)\n",
    "        elevations.append(node[1].elevation)\n",
    "        xcoordinates.append(node[1].coordinates[0])\n",
    "        ycoordinates.append(node[1].coordinates[1])\n",
    "\n",
    "\n",
    "\n",
    "# Get the supply duration in minutes (/60) as an integer\n",
    "supply_duration=int(network.options.time.duration/60)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing Reservoirs Section\n",
    "For every demand node, an artificial reservoir (AR) will be added at an elevation of $E_{reservoir}=E_{Demand\\,Node}+H^{min}$  \n",
    "Raising the elevation by $H^{min}$ enforces the minimum pressure threshold as no flow to the user would occur if the pressure at the node is less than that value  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adds \"AR\" to each demand node id to be used as ID for AR\n",
    "reservoirids=[\"AR\"+str(id) for id in demand_nodes]\n",
    "# Calculates the elevation of the AR\n",
    "reservoir_elevs=[elevation + minimum_pressure for elevation in elevations ]\n",
    "# No Patterns are assigned to any of the ARs\n",
    "reservoir_patterns=[\"    \"]*len(reservoirids)\n",
    "# Semicolons to end each line\n",
    "semicolons=[\";\"]*len(reservoirids)\n",
    "# Dataframe with all the required fields for AR [ID   Elevation   Pattern   ;]\n",
    "added_reservoirs=pd.DataFrame(list(zip(reservoirids,reservoir_elevs,reservoir_patterns,semicolons)))\n",
    "# Exports the added reservoirs as a list of strings where each entry is a line of the reservoirs section\n",
    "added_reservoirs=added_reservoirs.to_string(header=False,index=False).splitlines()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing Added Pipes\n",
    "Similar to the tanks section, each field for the pipe entries is stored in a separate list  \n",
    "The added pipes connect the created tanks to the original demand nodes and are responsible for simulating the pressure-dependent flow relationship  \n",
    "The length of the pipe is calculated according to the required head flow relationship dictated by the minimum and desired pressure as:  \n",
    "$$L=(H^{des}-H^{min})\\frac{C^{1.852}D^{4.87}}{10.67Q_{des}^{1.852}}$$  \n",
    "The diameter is unified at 0.05 m (50 mm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adds the phrase PipeforNode to each node id and stores it as a pipe id\n",
    "pipeids=['PipeforNode'+str(id) for id in demand_nodes]\n",
    "# Calculates the length of each pipe to simulate the head-flow relationship\n",
    "lengths=[round(pressure_diff*130**1.852*0.05**4.87/10.67/(demand)**1.852,4) for demand in desired_demands]\n",
    "# Sets all diameters to 1 m (1000 mm)\n",
    "diameters_pipes=[50]*len(pipeids)\n",
    "# Sets all Hazen-Williams Coefficients as 130\n",
    "hazen=[130]*len(pipeids)\n",
    "# Sets all created pipes to work as Check Valved to prevent backflow\n",
    "status=['CV']*len(pipeids)\n",
    "# sets all minor loss to 0\n",
    "minorloss=[0]*len(pipeids)\n",
    "# Assemble all lists into a dataframe where each row is the definition for one simple tank\n",
    "added_pipes=pd.DataFrame(list(zip(pipeids,demand_nodes,reservoirids,lengths,diameters_pipes,hazen,minorloss,status,semicolons)))\n",
    "# Exports the pipe section as a list of strings where each entry is a line of the pipes section\n",
    "added_pipes=added_pipes.to_string(header=False,index=False,col_space=10).splitlines()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing Reservoir Coordinates\n",
    "Each reservoir's coordinates are translated by a MM m in both x and y directions  \n",
    "The coordinates of the tank nodes are merely for display and do not affect the simulation in any way  \n",
    "[SCALE THESE VALUES FOR BETTER DISPLAY BASED ON YOUR INPUT FILE SCALE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Translates the tanks by a 100 m in both axes \n",
    "xcoordinates=[x+2 for x in xcoordinates]\n",
    "ycoordinates=[y+2 for y in ycoordinates]\n",
    "\n",
    "# Assemble all lists into a dataframe where each row is the coordinates for one simple tank\n",
    "added_coordinates=pd.DataFrame(list(zip(reservoirids,xcoordinates,ycoordinates)))\n",
    "# Exports the coordinate section as a list of strings where each entry is a line of the coordinates section\n",
    "added_coordinates=added_coordinates.to_string(header=False,index=False,col_space=10).splitlines()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rewriting Base Demands\n",
    "After creating the simple tanks, the base demands for all demand junctions has to be reset to zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of zero base demands for all nodes\n",
    "zerodemands=[0]*len(all_nodes)\n",
    "# White space indicating no patterns\n",
    "pattern=['     ']*len(all_nodes)\n",
    "semicolons=[';']*len(all_nodes)\n",
    "nodes=pd.DataFrame(list(zip(all_nodes,all_elevations,zerodemands,pattern,semicolons)))\n",
    "nodes=nodes.to_string(header=False,index=False).splitlines()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing the modified STM .inp File\n",
    "We first read through the original .inp file to find the line positions of each of the sections  \n",
    "Then each added or modified section is written into a new file and saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opens .inp file to read\n",
    "file=open(path,'r')\n",
    "lines=[]            # list to store all lines in the .inp file\n",
    "linecount=0         # Counter for the number of lines\n",
    "junctions_marker=0  # To store the line number at which the junctions section starts\n",
    "reservoirs_marker=0 # To store the line number at which the reservoir section ends\n",
    "pipes_marker=0      # To store the line number at which the pumps section starts\n",
    "coords_marker=0     # To store the line number at which the vertices section starts\n",
    "\n",
    "# Loops over each line in the input file \n",
    "for line in file:\n",
    "    # Record the position of the phrase [JUNCTIONS] and add 2 to skip the header line\n",
    "    if re.search('\\[JUNCTIONS\\]',line):\n",
    "        junctions_marker=linecount+2\n",
    "    # Record the position of the phrase [TANKS] and subtract 1 for the end of the reservoirs section\n",
    "    if re.search('\\[TANKS\\]',line):\n",
    "        reservoirs_marker=linecount-1\n",
    "     # Record the position of the phrase [PUMPS] and subtract 1 to add pipes to the end of the pipe section\n",
    "    if re.search('\\[PUMPS\\]',line):\n",
    "        pipes_marker=linecount-1\n",
    "     # Record the position of the phrase [Vertices] and subtract 1 to add Tank cooridnates to the end of the coordinates section\n",
    "    if re.search('\\[VERTICES\\]',line):\n",
    "        coords_marker=linecount-1\n",
    "    linecount+=1\n",
    "    # Store all lines in a list\n",
    "    lines.append(line)\n",
    "file.close()\n",
    "\n",
    "# Translate the pipes marker by the length of the tank section that will be added before it (as it will displace all subsequent lines)\n",
    "pipes_marker+=len(added_reservoirs)\n",
    "# Translate the coordinates marker by the length of the added tanks and pipes\n",
    "coords_marker+=len(added_reservoirs)+len(added_pipes)\n",
    "\n",
    "# Inserts the created sections in their appropriate location in the list of lines\n",
    "lines[junctions_marker:junctions_marker+len(nodes)]=nodes\n",
    "lines[reservoirs_marker:reservoirs_marker]=added_reservoirs\n",
    "lines[pipes_marker:pipes_marker]=added_pipes\n",
    "lines[coords_marker:coords_marker]=added_coordinates\n",
    "\n",
    "# Opens a new file in the same directory to write the modified network .inp file in\n",
    "file=open(path.parent / (name_only+'_CV-Res.inp'),'w')\n",
    "c=0     #line counter\n",
    "\n",
    "# All lines added by this script are missing a new line character at the end, the conditional statements below add the new line character for these lines only and writes all lines to the file\n",
    "for line in lines:\n",
    "    if c>=junctions_marker and c<=junctions_marker+len(nodes):\n",
    "        file.write(line+'\\n')\n",
    "    elif c>=reservoirs_marker and c<=reservoirs_marker+len(added_reservoirs):\n",
    "        file.write(line+'\\n')\n",
    "    elif c>=pipes_marker and c<=pipes_marker+len(added_pipes):\n",
    "        file.write(line+'\\n')\n",
    "    elif c>=coords_marker and c<=coords_marker+len(added_coordinates):\n",
    "        file.write(line+'\\n')\n",
    "    else: file.write(line)    \n",
    "    c+=1\n",
    "file.close()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References:\n",
    "##### [1] S. Mohapatra, A. Sargaonkar, and P. K. Labhasetwar, “Distribution Network Assessment using EPANET for Intermittent and Continuous Water Supply,” Water Resources Management, vol. 28, no. 11, pp. 3745–3759, Sep. 2014, doi: 10.1007/s11269-014-0707-y.\n",
    "##### [2] B. M. Janet Wagner, U. Shamir, and D. H. Marks, “WATER DISTRIBUTION RELIABILITY: SIMULATION METHODS.”"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
