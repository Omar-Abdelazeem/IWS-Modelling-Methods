{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting a Normal EPANET .inp File to a FCV-EM IWS File [1]\n",
    "This notebook takes an input EPANET files with demands input normally as a CWS base demand and adds the necessary elements to convert it into a FCV-Emitter (FCV-EM) IWS simulation  \n",
    "For details on the FCV-EM method refer to [1]  \n",
    "A simplified schematic of the modified demand node in FCV-EM is seen below:  \n",
    "  \n",
    "  \n",
    "![](FCVEM.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, we import the necessary libraries and packages\n",
    "**WNTR** for building EPANET network models in Python  \n",
    "**NUMPY & PANDAS** for data handling and processing  \n",
    "**re** for searching and matching text in the .inp file using regular expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wntr  \n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specifying paths for simulation files and preprocessing the input\n",
    "**Warning:** *Paths in this script (and the rest of this repo) are absolute unless running the network files provided within the repo*  \n",
    "Input filename (with extensions) as string.  \n",
    "For running the .inp files in this repository, you can use this relative path `\"../Network-Files/Network X/\"` where X is the network number "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected File:  Network3_12hr_\n"
     ]
    }
   ],
   "source": [
    " # Replace with appropriate path and filename\n",
    "directory='/Users/omaraliamer/Desktop/UofT/Publications/How to Model IWS/Github/IWS-Modelling-Methods-Repo/Network-Files/Network 3/'\n",
    "filename='Network3_12hr_PDA.inp'\n",
    "name_only=filename[0:-7]\n",
    "print(\"Selected File: \",name_only)\n",
    "abs_path=directory+filename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Necessary Assumptions Input\n",
    "Converting a CWS demand-driven analysis into an IWS pressure-driven analysis requires some assumptions in all methods  \n",
    "The resistance of the service connection between the demand node and the household (end-user) is uncertain and is modelled using two assumptions  \n",
    "The **desired head (pressure)** is the pressure at the demand node at which (or above) the consumer can satisfy their full demand in the supply duration (or possible less)  \n",
    "The **minimum head (pressure)** is the minimum pressure at the demand node required for flow to begin passing through the service connection  \n",
    "These two assumptions dictate the flow-pressure relationship that determines the pressure-dependent flow through the service connection as follows:\n",
    "\n",
    "$$ Q\\, = \\!Q_{des}\\sqrt{\\frac{H_{j}-H^{min}}{H^{des}-H^{min}}} \\quad[1]$$ \n",
    "Where Q is the flow through the service connection, $Q_{des}$ is the desired (base) demand, $H_j$ is the head at the demand node $j$, $H^{min}$ is the minimum head, and $H^{des}$ is the desired head\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_pressure=10     # Set the desired pressure\n",
    "minimum_pressure=0      # Set the minimum pressure\n",
    "pressure_diff=desired_pressure-minimum_pressure  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting information from the input file\n",
    "To modify the .inp file, demand node IDs, elevations, x and y coordinates  \n",
    "We use wntr to build the network model of the input file and use wntr's junctions module to extract the details of each node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "demand_nodes=[]       # For storing list of nodes that have non-zero demands\n",
    "desired_demands=[]    # For storing demand rates desired by each node for desired volume calculations\n",
    "elevations=[]         # For storing elevations of demand nodes\n",
    "xcoordinates=[]       # For storing x coordinates of demand nodes\n",
    "ycoordinates=[]       # For storing y coordinates of demand nodes\n",
    "all_nodes=[]          # For storing list of node ids of all nodes\n",
    "all_elevations=[]     # For storing elevations of all nodes\n",
    "## MAYBE SAVE ALL NODE IDS IN DATAFRAME WITH ELEVATION AND BASE DEMAND AND THEN FILTER DATA FRAME LATER FOR DEMAND NODES ONLY\n",
    "\n",
    "# Creates a network model object using EPANET .inp file\n",
    "network=wntr.network.WaterNetworkModel(abs_path)\n",
    "\n",
    "# Iterates over the junction list in the Network object\n",
    "for node in network.junctions():\n",
    "    all_nodes.append(node[1].name)\n",
    "    all_elevations.append(node[1].elevation)\n",
    "    # For all nodes that have non-zero demands\n",
    "    if node[1].base_demand != 0:\n",
    "        # Record node ID (name), desired demand (base_demand) in CMS, elevations, x and y coordinates\n",
    "        demand_nodes.append(node[1].name)\n",
    "        desired_demands.append(node[1].base_demand)\n",
    "        elevations.append(node[1].elevation)\n",
    "        xcoordinates.append(node[1].coordinates[0])\n",
    "        ycoordinates.append(node[1].coordinates[1])\n",
    "\n",
    "\n",
    "\n",
    "# Get the supply duration in minutes (/60) as an integer\n",
    "supply_duration=int(network.options.time.duration/60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing Emitters Section\n",
    "For every demand node, an emitter will be added to simulate the pressure-dependent demand withdrawal using the emitter coefficient  \n",
    "Each emitter's elevation is raised by $H^{min}$ to enforce the minimum pressure threshold as no flow to the user would occur if the pressure at the node is less than that value  \n",
    "The emitter's coefficient can be found as:  \n",
    "$$C_E=\\frac{Q_{des}}{\\sqrt{H^{des}-H^{min}}}$$  \n",
    "Where $C_E$ is the emitter's coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adds \"EM\" to each demand node id to be used as ID for the corresponding emitter\n",
    "emitterids=[\"EM\"+str(id) for id in demand_nodes]\n",
    "# Calculates the emitter coefficients \n",
    "emitter_coeffs=[demand*1000/np.sqrt(pressure_diff) for demand in desired_demands]\n",
    "# Semicolons to end each line\n",
    "semicolons=[\";\"]*len(emitterids)\n",
    "# Dataframe with all the required fields for Emitters [ID   Coefficient   ;]\n",
    "added_emitters=pd.DataFrame(list(zip(emitterids,emitter_coeffs,semicolons)))\n",
    "# Exports the added reservoirs as a list of strings where each entry is a line of the reservoirs section\n",
    "added_emitters=added_emitters.to_string(header=False,index=False).splitlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing Artificial Nodes\n",
    "As seen in the figure above, each demand nodes will require the addition of an Artificial Nodes (AN) to connect the FCV to the Emitter   \n",
    "The artificial node for Node X (will be named ANforNodeX) will have the same elevation as Node X  \n",
    "Additionally, emitters must also be defined as nodes. Thus nodes with the same ids as the emitters must be added  \n",
    "The Emitter nodes will also have no demand, but will have an elevation of $E+H^{min}$ where $E$ is the original node's elevation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adds the phrase \"AN1forNode\" to each node id as the id of the first artificial node (AN) added to each demand node\n",
    "anodeids=[\"ANforNode\"+str(id) for id in demand_nodes]\n",
    "# Sets the base demand for all added nodes as 0\n",
    "base_demands=[0]*len(anodeids)\n",
    "# No demand pattern is assigned to any demand node\n",
    "demand_patterns=[\"     \"]*len(anodeids)\n",
    "# Semicolons to end each line\n",
    "semicolons=[\";\"]*len(anodeids)\n",
    "# Dataframe with all the required fields for AN1 [ID   Elevation   Demand   Pattern   ;]\n",
    "added_nodes=pd.DataFrame(list(zip(anodeids,elevations,base_demands,demand_patterns,semicolons)))\n",
    "#DataFrame with the emitter nodes\n",
    "emitter_nodes=pd.DataFrame(list(zip(emitterids,elevations,base_demands,demand_patterns,semicolons)))\n",
    "# append emitter nodes to artificial nodes\n",
    "added_nodes=pd.concat([added_nodes,emitter_nodes])\n",
    "# Exports the added junctions as a list of strings where each entry is a line of the junctions section\n",
    "added_nodes=added_nodes.to_string(header=False,index=False,col_space=10).splitlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing Added Pipes\n",
    "FCV-EM method requires the addition of one pipe (Refer to the above figure)  \n",
    "The pipe should have a negligible major loss and no minor loss  \n",
    "The diameter is unified at 0.35 m for simplicity (350 mm)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adds the phrase PipeforNode to each node id and stores it as a pipe id\n",
    "pipeids=['Pipe1forNode'+str(id) for id in demand_nodes]\n",
    "# sets minor loss coefficients to zero\n",
    "minorloss=[0]*len(pipeids)\n",
    "# Sets all lengths to 0.1 m\n",
    "lengths=[0.1]*len(pipeids)\n",
    "# Sets all diameters to 1 m (1000 mm)\n",
    "diameters_pipes=[350]*len(pipeids)\n",
    "# Sets all Hazen-Williams Coefficients as 130\n",
    "hazen=[130]*len(pipeids)\n",
    "# Sets all created pipes to work as Check Valved to prevent backflow\n",
    "status=['CV']*len(pipeids)\n",
    "# list of semicolons\n",
    "semicolons=[\";\"]*len(pipeids)\n",
    "# Assemble all lists into a dataframe where each row is the definition for one simple reservoir\n",
    "# Data frame with all required fields [ID   Node1   Node2   Length   Diameter   Roughness   MinorLoss   Status   ;]\n",
    "added_pipes=pd.DataFrame(list(zip(pipeids,demand_nodes,anodeids,lengths,diameters_pipes,hazen,minorloss,status,semicolons)))\n",
    "# Exports the pipe section as a list of strings where each entry is a line of the pipes section\n",
    "added_pipes=added_pipes.to_string(header=False,index=False,col_space=10).splitlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing Valves Section\n",
    "For each original demand node, a Flow-Control Valve is added restrict the flow to the users desired flow rate $Q^{des}$  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adds the phrase APSVforNode to each node id and stores it as a PSV valve id\n",
    "valveids=[\"FCVforNode\"+str(id) for id in demand_nodes]\n",
    "# From nodes are the original demand nodes and to nodes are the artificial nodes\n",
    "# Sets all valve diameters to 12 (will not affect head loss across valve)\n",
    "valve_diameters=[12.0000]*len(valveids)\n",
    "# Sets the type of all valves to Flow-Control Valves\n",
    "valve_types=[\"FCV\"]*len(valveids)\n",
    "# Sets the valve setting for each valve to the base demand of the original demand nodes (converts back to LPS)\n",
    "valve_settings=[demand*1000 for demand in desired_demands]\n",
    "# Sets the minor loss coefficient across the valve to 0\n",
    "valve_minor_loss=[\"0.0000\"]*len(valveids)\n",
    "# Semicolons at the end of each line\n",
    "semicolons=[';']*len(valveids)\n",
    "# Data frame with all required fields [ID   Node1   Node2   Diameter   Type   Setting   MinorLoss   ;]\n",
    "added_valves=pd.DataFrame(list(zip(valveids,anodeids,emitterids,valve_diameters,valve_types,valve_settings,valve_minor_loss,semicolons)))\n",
    "added_valves=added_valves.to_string(header=False,index=False,col_space=10).splitlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing AN & Emitter Coordinates  \n",
    "Each emitter's coordinates are translated by a ZZ m in both x and y directions  \n",
    "The ANs will be translated MM meters in both directions  \n",
    "These coordinates are merely for display and do not affect the simulation in any way  \n",
    "[SCALE THESE VALUES FOR BETTER DISPLAY BASED ON YOUR INPUT FILE SCALE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set preferred translation distance for [AN1,AN2,AT] where AN is Artificial Node and AT is the Artifical Tank\n",
    "x_direct_distance=[30,60]\n",
    "y_driect_distance=[-30,0]\n",
    "# Translates the reservoirs by a 100 m in both axes \n",
    "anode_xcoord=[x+x_direct_distance[0] for x in xcoordinates]\n",
    "emitter_xcoord =[x+x_direct_distance[1] for x in xcoordinates]\n",
    "anode_ycoord=[y+y_driect_distance[0] for y in ycoordinates]\n",
    "emitter_ycoord =[y+y_driect_distance[1] for y in ycoordinates]\n",
    "\n",
    "added_xcoordinates=anode_xcoord+emitter_xcoord\n",
    "added_ycoordinates=anode_ycoord+emitter_ycoord\n",
    "ids_coords=anodeids+emitterids\n",
    "\n",
    "# Assemble all lists into a dataframe where each row is the coordinates for one artificial reservoir or node\n",
    "added_coordinates=pd.DataFrame(list(zip(ids_coords,added_xcoordinates,added_ycoordinates)))\n",
    "# Exports the coordinate section as a list of strings where each entry is a line of the coordinates section\n",
    "added_coordinates=added_coordinates.to_string(header=False,index=False,col_space=10).splitlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rewriting Base Demands\n",
    "After creating the required additions to the original demand nodes, the base demands for all demand junctions has to be reset to zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of zero base demands for all nodes\n",
    "zerodemands=[0]*len(all_nodes)\n",
    "# White space indicating no patterns\n",
    "pattern=['     ']*len(all_nodes)\n",
    "semicolons=[';']*len(all_nodes)\n",
    "original_nodes=pd.DataFrame(list(zip(all_nodes,all_elevations,zerodemands,pattern,semicolons)))\n",
    "original_nodes=original_nodes.to_string(header=False,index=False,col_space=10).splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opens .inp file to read\n",
    "file=open(abs_path,'r')\n",
    "lines=[]            # list to store all lines in the .inp file\n",
    "linecount=0         # Counter for the number of lines\n",
    "junctions_marker=0  # To store the line number at which the junctions section starts\n",
    "emitters_marker=0   # To store the line number at which the emitter section starts\n",
    "pipes_marker=0      # To store the line number at which the pumps section starts\n",
    "valves_marker=0     # to store the line number at which the valves section\n",
    "coords_marker=0     # To store the line number at which the vertices section starts\n",
    "exponent_line=0     # To store the line number of teh emitter exponent option\n",
    "\n",
    "# Loops over each line in the input file \n",
    "for line in file:\n",
    "    # Record the position of the phrase [JUNCTIONS] and add 2 to skip the header line\n",
    "    if re.search('\\[JUNCTIONS\\]',line):\n",
    "        junctions_marker=linecount+2\n",
    "    # Record the position of the phrase [TANKS] and add 2 to skip the header line\n",
    "    if re.search('\\[EMITTERS\\]',line):\n",
    "        emitters_marker=linecount+2\n",
    "     # Record the position of the phrase [PUMPS] and subtract 1 to add pipes to the end of the pipe section\n",
    "    if re.search('\\[PUMPS\\]',line):\n",
    "        pipes_marker=linecount-1\n",
    "    # Record the position of the phrase [VALVES] and add 2 to skip the header line\n",
    "    if re.search('\\[VALVES\\]',line):\n",
    "        valves_marker=linecount+2\n",
    "     # Record the position of the phrase [Vertices] and subtract 1 to add Tank cooridnates to the end of the coordinates section\n",
    "    if re.search('\\[VERTICES\\]',line):\n",
    "        coords_marker=linecount-1\n",
    "    if re.search('Emitter Exponent',line):\n",
    "        exponent_line=linecount\n",
    "    linecount+=1\n",
    "    # Store all lines in a list\n",
    "    lines.append(line)\n",
    "file.close()\n",
    "\n",
    "\n",
    "# Translate the pipes marker by the length of the added nodes that will be added before it (as it will displace all subsequent lines)\n",
    "pipes_marker+=len(added_nodes)\n",
    "# Translate the valves marker by the length of the added nodes, pipes\n",
    "valves_marker+=len(added_pipes)+len(added_nodes)\n",
    "# Translate the emitters marker by the length of the added nodes, pipes and valves\n",
    "emitters_marker+=len(added_valves)+len(added_pipes)+len(added_nodes)\n",
    "# Translate the coordinates marker by the length of the added tanks, pipes and valves\n",
    "coords_marker+=len(added_emitters)+len(added_pipes)+len(added_valves)+len(added_nodes)\n",
    "\n",
    "# Inserts the created sections in their appropriate location in the list of lines\n",
    "lines[exponent_line]=\"Emitter Exponent      0.5000\\n\"\n",
    "lines[junctions_marker:junctions_marker+len(original_nodes)]=original_nodes\n",
    "lines[junctions_marker+len(original_nodes):junctions_marker+len(original_nodes)]=added_nodes\n",
    "lines[pipes_marker:pipes_marker]=added_pipes\n",
    "lines[valves_marker:valves_marker]=added_valves\n",
    "lines[emitters_marker:emitters_marker]=added_emitters\n",
    "lines[coords_marker:coords_marker]=added_coordinates\n",
    "\n",
    "# Opens a new file in the same directory to write the modified network .inp file in\n",
    "file=open(directory+name_only+'FCV-EM.inp','w')\n",
    "c=0     #line counter\n",
    "\n",
    "# All lines added by this script are missing a new line character at the end, the conditional statements below add the new line character for these lines only and writes all lines to the file\n",
    "for line in lines:\n",
    "    if c>=junctions_marker and c<=junctions_marker+len(original_nodes)+len(added_nodes):\n",
    "        file.write(line+'\\n')\n",
    "    elif c>=emitters_marker and c<=emitters_marker+len(added_emitters):\n",
    "        file.write(line+'\\n')\n",
    "    elif c>=pipes_marker and c<=pipes_marker+len(added_pipes):\n",
    "        file.write(line+'\\n')\n",
    "    elif c>=valves_marker and c<=valves_marker+len(added_valves):\n",
    "        file.write(line+'\\n')\n",
    "    elif c>=coords_marker and c<=coords_marker+len(added_coordinates):\n",
    "        file.write(line+'\\n')\n",
    "    else: file.write(line)    \n",
    "    c+=1\n",
    "file.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References:\n",
    "##### [1] M. A. H. Abdy Sayyed, R. Gupta, and T. T. Tanyimboh, “Noniterative Application of EPANET for Pressure Dependent Modelling Of Water Distribution Systems,” Water Resources Management, vol. 29, no. 9, pp. 3227–3242, Jul. 2015, doi: 10.1007/s11269-015-0992-0."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "dd6a0ae2e89424b22bc0c3fd46707be6f981ef35bdac29f85707eba2fc78ecd7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
