{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting a Normal EPANET .inp File to a PSV IWS File [1]\n",
    "This notebook takes an input EPANET files with demands input normally as a CWS base demand and adds the necessary elements to convert it into a Simple Tank Method (STM) simulation  \n",
    "For details on the STM method refer to [1]  \n",
    "A simplified schematic of the modified demand node in PSV is seen below:  \n",
    "  \n",
    "  \n",
    "  \n",
    "![](PSV.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, we import the necessary libraries and packages\n",
    "**WNTR** for building EPANET network models in Python  \n",
    "**NUMPY & PANDAS** for data handling and processing  \n",
    "**re** for searching and matching text in the .inp file using regular expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wntr  \n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specifying paths for simulation files and preprocessing the input\n",
    "**Warning:** *Paths in this script (and the rest of this repo) are absolute*  \n",
    "Input filename (with extensions) as string.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected File:  N3a_4hr\n"
     ]
    }
   ],
   "source": [
    " # Replace with appropriate path and filename\n",
    "directory='/Users/omaraliamer/Desktop/UofT/Papers/Clean Network Files/SWMM/Final Files/'\n",
    "filename='N3a_4hr.inp'\n",
    "name_only=filename[0:-4]\n",
    "print(\"Selected File: \",name_only)\n",
    "abs_path=directory+filename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Necessary Assumptions Input\n",
    "Converting a CWS demand-driven analysis into an IWS pressure-driven analysis requires some assumptions in all methods  \n",
    "The resistance of the service connection between the demand node and the household (end-user) is uncertain and is modelled using two assumptions  \n",
    "The **desired head (pressure)** is the pressure at the demand node at which (or above) the consumer can satisfy their full demand in the supply duration (or possible less)  \n",
    "The **minimum head (pressure)** is the minimum pressure at the demand node required for flow to begin passing through the service connection  \n",
    "These two assumptions dictate the flow-pressure relationship that determines the pressure-dependent flow through the service connection as follows:\n",
    "\n",
    "$$ Q\\, = \\!Q_{des}\\sqrt{\\frac{H_{j}-H^{min}}{H^{des}-H^{min}}} \\quad[2]$$ \n",
    "Where Q is the flow through the service connection, $Q_{des}$ is the desired (base) demand, $H_j$ is the head at the demand node $j$, $H^{min}$ is the minimum head, and $H^{des}$ is the desired head\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_pressure=10     # Set the desired pressure\n",
    "minimum_pressure=0      # Set the minimum pressure\n",
    "pressure_diff=desired_pressure-minimum_pressure  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting information from the input file\n",
    "To modify the .inp file, demand node IDs, elevations, x and y coordinates  \n",
    "We use wntr to build the network model of the input file and use wntr's junctions module to extract the details of each node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "demand_nodes=[]       # For storing list of nodes that have non-zero demands\n",
    "desired_demands=[]    # For storing demand rates desired by each node for desired volume calculations\n",
    "elevations=[]         # For storing elevations of demand nodes\n",
    "xcoordinates=[]       # For storing x coordinates of demand nodes\n",
    "ycoordinates=[]       # For storing y coordinates of demand nodes\n",
    "all_nodes=[]          # For storing list of node ids of all nodes\n",
    "all_elevations=[]     # For storing elevations of all nodes\n",
    "## MAYBE SAVE ALL NODE IDS IN DATAFRAME WITH ELEVATION AND BASE DEMAND AND THEN FILTER DATA FRAME LATER FOR DEMAND NODES ONLY\n",
    "\n",
    "# Creates a network model object using EPANET .inp file\n",
    "network=wntr.network.WaterNetworkModel(abs_path)\n",
    "\n",
    "# Iterates over the junction list in the Network object\n",
    "for node in network.junctions():\n",
    "    all_nodes.append(node[1].name)\n",
    "    all_elevations.append(node[1].elevation)\n",
    "    # For all nodes that have non-zero demands\n",
    "    if node[1].base_demand != 0:\n",
    "        # Record node ID (name), desired demand (base_demand) in CMS, elevations, x and y coordinates\n",
    "        demand_nodes.append(node[1].name)\n",
    "        desired_demands.append(node[1].base_demand)\n",
    "        elevations.append(node[1].elevation)\n",
    "        xcoordinates.append(node[1].coordinates[0])\n",
    "        ycoordinates.append(node[1].coordinates[1])\n",
    "\n",
    "# Get the supply duration in minutes (/60) as an integer\n",
    "supply_duration=int(network.options.time.duration/60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing Tank Section\n",
    "Each Simple Tank represents the demand volume of the respective demand node throughout the supply cycle  \n",
    "The volume of each Simple Tank is calculated is:  \n",
    "$$ V_{des}\\,=\\,Q_{des}\\,(m^3/s)\\,\\times\\,60\\,(s/min)\\,\\times\\,Supply\\,Duration\\,(min)$$  \n",
    "Using the desired volume, and unifying tank height at 1 m (for ease of postprocessin), the diameter of the tank can be calculated as:  \n",
    "$$D\\,(m)\\,=\\sqrt{\\frac{4V_{des}}{\\pi}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adds the phrase TankforNode to each node id and stores it as a tank id\n",
    "tankids=['ATforNode'+str(id) for id in demand_nodes] \n",
    "# Calculate desired demand volumes and then calculates the diameters of the simple tanks\n",
    "volumes=[demand* 60 * supply_duration for demand in desired_demands]\n",
    "diameters_tanks=[round(np.sqrt(volume * 4 / np.pi),4) for volume in volumes]\n",
    "# Calculates the elevations of the ATs as the elevation of their original demand node - 1 m\n",
    "tank_elevations=[elevation-1 for elevation in elevations]\n",
    "# List of zeros for each tank to be used as the values for Initial Level, Minimum Level, and Minimum Volume \n",
    "zeros=[0.0000] *len(tankids)\n",
    "# Sets Maximum levels for all tanks as 1\n",
    "MaxLevel=[1.0000]*len(tankids)\n",
    "# No Volume curve is assigned to any of the tanks\n",
    "VolCurve=['    ']*len(tankids)\n",
    "# Semicolons to end each tank line\n",
    "semicolons=[';']*len(tankids)\n",
    "# Assemble all lists into a dataframe where each row is the definition for one simple tank\n",
    "# Required fields in EPANET .inp [ID   Elevation   InitLevel   MinLevel   MaxLevel    Diameter   MinVol    VolCurve   ;]\n",
    "tanks_section=pd.DataFrame(list(zip(tankids,tank_elevations,zeros,zeros,MaxLevel,diameters_tanks,zeros,VolCurve,semicolons)))\n",
    "# Exports the tank section as a list of strings where each entry is a line of the tanks section\n",
    "added_tanks=tanks_section.to_string(header=False,index=False,col_space=10).splitlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing Artificial Nodes\n",
    "As seen in the figure above, each demand nodes will require the addition of two Artificial Nodes (AN) to connect it to the PSV and the downstream tank  \n",
    "Both nodes will be at the same elevation of the demand node, will have no demand assigned, and no demand patterns  \n",
    "The first node for a demand node X will be named AN1forNodeX and the second will be AN2forNodeX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adds the phrase \"AN1forNode\" to each node id as the id of the first artificial node (AN) added to each demand node\n",
    "node1ids=[\"AN1forNode\"+str(id) for id in demand_nodes]\n",
    "# Adds the phrase \"AN2forNode\" to each node id as the id of the second artificial node (AN) added to each demand node\n",
    "node2ids=[\"AN2forNode\"+str(id) for id in demand_nodes]\n",
    "# Sets the base demand for all added nodes as 0\n",
    "base_demands=[0]*len(node1ids)\n",
    "# No demand pattern is assigned to any demand node\n",
    "demand_patterns=[\"     \"]*len(node1ids)\n",
    "# Dataframe with all the required fields for AN1 [ID   Elevation   Demand   Pattern   ;]\n",
    "nodes1=pd.DataFrame(list(zip(node1ids,elevations,base_demands,demand_patterns,semicolons)))\n",
    "# Dataframe with all the required fields for AN2 [ID   Elevation   Demand   Pattern   ;]\n",
    "nodes2=pd.DataFrame(list(zip(node2ids,elevations,base_demands,demand_patterns,semicolons)))\n",
    "# Joins both dataframes into one dataframe with all the added nodes\n",
    "added_nodes=pd.concat([nodes1,nodes2])\n",
    "# Exports the added junctions section as a list of strings where each entry is a line of the junctions section\n",
    "added_nodes=added_nodes.to_string(header=False,index=False,col_space=10).splitlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing Added Pipes\n",
    "Similar to the tanks section, each field for the pipe entries is stored in a separate list  \n",
    "PSV method requires the addition of two pipes (Refer to the above figure)  \n",
    "Both pipes according to [1] should have a small length (0.1 m), a diameter of 350 mm, a HW coefficient of 130, and a minor loss coefficient of:  \n",
    "$$ K_{Minor}=(H^{des}-H^{min})\\frac{g\\pi^2D^4}{8Q_{des}^2}$$\n",
    "The diameter is unified at 0.35 m for simplicity (50 mm)  \n",
    "While the second pipe will have a minor loss coefficient of 0, and serves to connect the PSV to the downstream artificial tank  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adds the phrase PipeforNode to each node id and stores it as a pipe id\n",
    "pipeids=['Pipe1forNode'+str(id) for id in demand_nodes]\n",
    "length=len(pipeids)\n",
    "pipeids.extend(['Pipe2forNode'+str(id) for id in demand_nodes])\n",
    "# From nodes\n",
    "from_node=demand_nodes+node2ids\n",
    "# to nodes\n",
    "to_node=node1ids+tankids\n",
    "# Calculates the minor loss coefficient of each pipe to simulate the head-flow relationship\n",
    "minorloss=[pressure_diff*9.81*np.pi**2*0.35**4/(8*demand**2) for demand in desired_demands]\n",
    "minorloss.extend([0]*length)\n",
    "# Sets all lengths to 0.1 m\n",
    "lengths=[0.1]*len(pipeids)\n",
    "# Sets all diameters to 1 m (1000 mm)\n",
    "diameters_pipes=[350]*len(pipeids)\n",
    "# Sets all Hazen-Williams Coefficients as 130\n",
    "hazen=[130]*len(pipeids)\n",
    "# Sets all created pipes to work as Check Valved to prevent backflow\n",
    "status=['CV']*len(pipeids)\n",
    "# list of semicolons\n",
    "semicolons=[\";\"]*len(pipeids)\n",
    "# Assemble all lists into a dataframe where each row is the definition for one simple tank\n",
    "# Data frame with all required fields [ID   Node1   Node2   Length   Diameter   Roughness   MinorLoss   Status   ;]\n",
    "added_pipes=pd.DataFrame(list(zip(pipeids,from_node,to_node,lengths,diameters_pipes,hazen,minorloss,status,semicolons)))\n",
    "# Exports the pipe section as a list of strings where each entry is a line of the pipes section\n",
    "added_pipes=added_pipes.to_string(header=False,index=False,col_space=10).splitlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing Valves Section\n",
    "For each original demand node, a Pressure-Sustaining Valve is added to maintain the upstream pressure (at AN1) at 0 to simulate the free outlet condition of a tank filling from the top  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adds the phrase APSVforNode to each node id and stores it as a PSV valve id\n",
    "valveids=[\"APSVforNode\"+str(id) for id in demand_nodes]\n",
    "# From nodes are the first artificial nodes (node1ids) and to nodes are the second artificial nodes (node2ids)\n",
    "# Sets all valve diameters to 12 (will not affect head loss across valve)\n",
    "valve_diameters=[12.0000]*len(valveids)\n",
    "# Sets the type of all valves to Pressure-Sustaining Valves\n",
    "valve_types=[\"PSV\"]*len(valveids)\n",
    "# Sets the valve setting (the pressure to sustain upstream of the valve in this case) to 0 (Atmospheric pressure to simulate a tank filling from the top)\n",
    "valve_settings=[\"0.0000\"]*len(valveids)\n",
    "# Sets the minor loss coefficient across the valve to 0\n",
    "valve_minor_loss=[\"0.0000\"]*len(valveids)\n",
    "# Semicolons at the end of each line\n",
    "semicolons=[';']*len(valveids)\n",
    "# Data frame with all required fields [ID   Node1   Node2   Diameter   Type   Setting   MinorLoss   ;]\n",
    "added_valves=pd.DataFrame(list(zip(valveids,node1ids,node2ids,valve_diameters,valve_types,valve_settings,valve_minor_loss,semicolons)))\n",
    "added_valves=added_valves.to_string(header=False,index=False,col_space=10).splitlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing Tank & AN Coordinates  \n",
    "Each tank's coordinates are translated by a 100 m in both x and y directions  \n",
    "The ANs will be translated 30 and 70 meters respectively in both directions  \n",
    "These coordinates are merely for display and do not affect the simulation in any way  \n",
    "[SCALE THESE VALUES FOR BETTER DISPLAY BASED ON YOUR INPUT FILE SCALE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set preferred translation distance for [AN1,AN2,AT] where AN is Artificial Node and AT is the Artifical Tank\n",
    "x_direct_distance=[30,70,100]\n",
    "y_driect_distance=[-30,0,-30]\n",
    "# Translates the tanks by a 100 m in both axes \n",
    "node1_xcoord=[x+x_direct_distance[0] for x in xcoordinates]\n",
    "node2_xcoord=[x+x_direct_distance[1] for x in xcoordinates]\n",
    "tank_xcoord =[x+x_direct_distance[2] for x in xcoordinates]\n",
    "node1_ycoord=[y+y_driect_distance[0] for y in ycoordinates]\n",
    "node2_ycoord=[y+y_driect_distance[1] for y in ycoordinates]\n",
    "tank_ycoord =[y+y_driect_distance[2] for y in ycoordinates]\n",
    "\n",
    "added_xcoordinates=node1_xcoord+node2_xcoord+tank_xcoord\n",
    "added_ycoordinates=node1_ycoord+node2_ycoord+tank_ycoord\n",
    "ids_coords=node1ids+node2ids+tankids\n",
    "##\n",
    "# Assemble all lists into a dataframe where each row is the coordinates for one simple tank\n",
    "added_coordinates=pd.DataFrame(list(zip(ids_coords,added_xcoordinates,added_ycoordinates)))\n",
    "# Exports the coordinate section as a list of strings where each entry is a line of the coordinates section\n",
    "added_coordinates=added_coordinates.to_string(header=False,index=False,col_space=10).splitlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rewriting Base Demands\n",
    "After creating the required additions to the original demand nodes, the base demands for all demand junctions has to be reset to zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of zero base demands for all nodes\n",
    "zerodemands=[0]*len(all_nodes)\n",
    "# White space indicating no patterns\n",
    "pattern=['     ']*len(all_nodes)\n",
    "semicolons=[';']*len(all_nodes)\n",
    "original_nodes=pd.DataFrame(list(zip(all_nodes,all_elevations,zerodemands,pattern,semicolons)))\n",
    "original_nodes=original_nodes.to_string(header=False,index=False,col_space=10).splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opens .inp file to read\n",
    "file=open(abs_path,'r')\n",
    "lines=[]            # list to store all lines in the .inp file\n",
    "linecount=0         # Counter for the number of lines\n",
    "junctions_marker=0  # To store the line number at which the junctions section starts\n",
    "tanks_marker=0      # To store the line number at which the tanks section starts\n",
    "pipes_marker=0      # To store the line number at which the pumps section starts\n",
    "valves_marker=0     # to store the line number at which the valves section\n",
    "coords_marker=0     # To store the line number at which the vertices section starts\n",
    "\n",
    "# Loops over each line in the input file \n",
    "for line in file:\n",
    "    # Record the position of the phrase [JUNCTIONS] and add 2 to skip the header line\n",
    "    if re.search('\\[JUNCTIONS\\]',line):\n",
    "        junctions_marker=linecount+2\n",
    "    # Record the position of the phrase [TANKS] and add 2 to skip the header line\n",
    "    if re.search('\\[TANKS\\]',line):\n",
    "        tanks_marker=linecount+2\n",
    "     # Record the position of the phrase [PUMPS] and subtract 1 to add pipes to the end of the pipe section\n",
    "    if re.search('\\[PUMPS\\]',line):\n",
    "        pipes_marker=linecount-1\n",
    "    # Record the position of the phrase [VALVES] and add 2 to skip the header line\n",
    "    if re.search('\\[VALVES\\]',line):\n",
    "        valves_marker=linecount+2\n",
    "     # Record the position of the phrase [Vertices] and subtract 1 to add Tank cooridnates to the end of the coordinates section\n",
    "    if re.search('\\[VERTICES\\]',line):\n",
    "        coords_marker=linecount-1\n",
    "    linecount+=1\n",
    "    # Store all lines in a list\n",
    "    lines.append(line)\n",
    "file.close()\n",
    "\n",
    "# Translate the tanks marker by the length of the added nodes (ANs) that will be added before it (as it will displace all subsequent lines)\n",
    "tanks_marker+=len(added_nodes)\n",
    "# Translate the pipes marker by the length of the tank section that will be added before it (as it will displace all subsequent lines)\n",
    "pipes_marker+=len(added_tanks)+len(added_nodes)\n",
    "# Translate the coordinates marker by the length of the added tanks, pipes and valves\n",
    "valves_marker+=len(added_tanks)+len(added_pipes)+len(added_nodes)\n",
    "# Translate the coordinates marker by the length of the added tanks, pipes and valves\n",
    "coords_marker+=len(added_tanks)+len(added_pipes)+len(added_valves)+len(added_nodes)\n",
    "\n",
    "# Inserts the created sections in their appropriate location in the list of lines\n",
    "lines[junctions_marker:junctions_marker+len(original_nodes)]=original_nodes\n",
    "lines[junctions_marker+len(original_nodes):junctions_marker+len(original_nodes)]=added_nodes\n",
    "lines[tanks_marker:tanks_marker]=added_tanks\n",
    "lines[pipes_marker:pipes_marker]=added_pipes\n",
    "lines[valves_marker:valves_marker]=added_valves\n",
    "lines[coords_marker:coords_marker]=added_coordinates\n",
    "\n",
    "# Opens a new file in the same directory to write the modified network .inp file in\n",
    "file=open(directory+name_only+'_PSV_Generated.inp','w')\n",
    "c=0     #line counter\n",
    "\n",
    "# All lines added by this script are missing a new line character at the end, the conditional statements below add the new line character for these lines only and writes all lines to the file\n",
    "for line in lines:\n",
    "    if c>=junctions_marker and c<=junctions_marker+len(original_nodes)+len(added_nodes):\n",
    "        file.write(line+'\\n')\n",
    "    elif c>=tanks_marker and c<=tanks_marker+len(tanks_section):\n",
    "        file.write(line+'\\n')\n",
    "    elif c>=pipes_marker and c<=pipes_marker+len(added_pipes):\n",
    "        file.write(line+'\\n')\n",
    "    elif c>=valves_marker and c<=valves_marker+len(added_valves):\n",
    "        file.write(line+'\\n')\n",
    "    elif c>=coords_marker and c<=coords_marker+len(added_coordinates):\n",
    "        file.write(line+'\\n')\n",
    "    else: file.write(line)    \n",
    "    c+=1\n",
    "file.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [1] P. Sivakumar, N. B. Gorev, T. T. Tanyimboh, I. F. Kodzhespirova, C. R. Suribabu, and T. R. Neelakantan, “Dynamic Pressure-Dependent Simulation of Water Distribution Networks Considering Volume-Driven Demands Based on Noniterative Application of EPANET 2,” Journal of Water Resources Planning and Management, vol. 146, no. 6, p. 06020005, Jun. 2020, doi: 10.1061/(asce)wr.1943-5452.0001220.\n",
    "#### [2] B. M. Janet Wagner, U. Shamir, and D. H. Marks, “WATER DISTRIBUTION RELIABILITY: SIMULATION METHODS.”"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
