{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting a Normal EPANET .inp File to a FCV-Res IWS File [1]\n",
    "This notebook takes an input EPANET files with demands input normally as a CWS base demand and adds the necessary elements to convert it into a FCV-Reservoir (FCVRes) IWS simulation  \n",
    "For details on the FCVRes method refer to [1]   \n",
    "A simplified schematic of the modified demand node in FCVRes is seen below:  \n",
    "\n",
    "![](FCVRes.png)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, we import the necessary libraries and packages\n",
    "**WNTR** for building EPANET network models in Python  \n",
    "**NUMPY & PANDAS** for data handling and processing  \n",
    "**re** for searching and matching text in the .inp file using regular expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wntr  \n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import re\n",
    "import pathlib"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specifying paths for simulation files and preprocessing the input\n",
    "**Warning:** *Paths in this script (and the rest of this repo) are absolute unless running the network files provided within the repo*  \n",
    "Input filename (with extensions) as string.  \n",
    "For running the .inp files in this repository, you can use this relative path `\"../Network-Files/Network X/\"` where X is the network number "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected File:  Network3_4hr_\n"
     ]
    }
   ],
   "source": [
    " # Replace with appropriate path and filename\n",
    "directory=pathlib.Path(\"../Network-Files/Network 3\")\n",
    "filename=pathlib.Path(\"Network3_4hr_PDA.inp\")\n",
    "name_only=str(filename.stem)[0:-4]\n",
    "print(\"Selected File: \",name_only)\n",
    "abs_path=directory/filename"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Necessary Assumptions Input\n",
    "Converting a CWS demand-driven analysis into an IWS pressure-driven analysis requires some assumptions in all methods  \n",
    "The resistance of the service connection between the demand node and the household (end-user) is uncertain and is modelled using two assumptions  \n",
    "The **desired head (pressure)** is the pressure at the demand node at which (or above) the consumer can satisfy their full demand in the supply duration (or possible less)  \n",
    "The **minimum head (pressure)** is the minimum pressure at the demand node required for flow to begin passing through the service connection  \n",
    "These two assumptions dictate the flow-pressure relationship that determines the pressure-dependent flow through the service connection as follows:\n",
    "\n",
    "$$ Q\\, = \\!Q_{des}(\\frac{H_{j}-H^{min}}{H^{des}-H^{min}})^{\\frac{1}{n_j}} \\quad[1]$$ \n",
    "Where Q is the flow through the service connection, $Q_{des}$ is the desired (base) demand, $H_j$ is the head at the demand node $j$, $H^{min}$ is the minimum head, and $H^{des}$ is the desired head\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_pressure=10     # Set the desired pressure\n",
    "minimum_pressure=0      # Set the minimum pressure\n",
    "### Nj=0.5\n",
    "pressure_diff=desired_pressure-minimum_pressure  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting information from the input file\n",
    "To modify the .inp file, demand node IDs, elevations, x and y coordinates  \n",
    "We use wntr to build the network model of the input file and use wntr's junctions module to extract the details of each node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "demand_nodes=[]       # For storing list of nodes that have non-zero demands\n",
    "desired_demands=[]    # For storing demand rates desired by each node for desired volume calculations\n",
    "elevations=[]         # For storing elevations of demand nodes\n",
    "xcoordinates=[]       # For storing x coordinates of demand nodes\n",
    "ycoordinates=[]       # For storing y coordinates of demand nodes\n",
    "all_nodes=[]          # For storing list of node ids of all nodes\n",
    "all_elevations=[]     # For storing elevations of all nodes\n",
    "\n",
    "# Creates a network model object using EPANET .inp file\n",
    "network=wntr.network.WaterNetworkModel(abs_path)\n",
    "\n",
    "# Iterates over the junction list in the Network object\n",
    "for node in network.junctions():\n",
    "    all_nodes.append(node[1].name)\n",
    "    all_elevations.append(node[1].elevation)\n",
    "    # For all nodes that have non-zero demands\n",
    "    if node[1].base_demand != 0:\n",
    "        # Record node ID (name), desired demand (base_demand) in CMS, elevations, x and y coordinates\n",
    "        demand_nodes.append(node[1].name)\n",
    "        desired_demands.append(node[1].base_demand)\n",
    "        elevations.append(node[1].elevation)\n",
    "        xcoordinates.append(node[1].coordinates[0])\n",
    "        ycoordinates.append(node[1].coordinates[1])\n",
    "\n",
    "# Get the supply duration in minutes (/60) as an integer\n",
    "supply_duration=int(network.options.time.duration/60)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing Reservoirs Section\n",
    "For every demand node, an artificial reservoir (AR) will be added at an elevation of $E_{reservoir}=E_{Demand\\,Node}+H^{min}$  \n",
    "Raising the elevation by $H^{min}$ enforces the minimum pressure threshold as no flow to the user would occur if the pressure at the node is less than that value  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adds \"AR\" to each demand node id to be used as ID for AR\n",
    "reservoirids=[\"AR\"+str(id) for id in demand_nodes]\n",
    "# Calculates the elevation of the AR\n",
    "reservoir_elevs=[elevation + minimum_pressure for elevation in elevations ]\n",
    "# No Patterns are assigned to any of the ARs\n",
    "reservoir_patterns=[\"    \"]*len(reservoirids)\n",
    "# Semicolons to end each line\n",
    "semicolons=[\";\"]*len(reservoirids)\n",
    "# Dataframe with all the required fields for AR [ID   Elevation   Pattern   ;]\n",
    "added_reservoirs=pd.DataFrame(list(zip(reservoirids,reservoir_elevs,reservoir_patterns,semicolons)))\n",
    "# Exports the added reservoirs as a list of strings where each entry is a line of the reservoirs section\n",
    "added_reservoirs=added_reservoirs.to_string(header=False,index=False).splitlines()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing Artificial Nodes\n",
    "As seen in the figure above, each demand nodes will require the addition of an Artificial Nodes (AN) to connect the FCV to the AR  \n",
    "The artificial node for Node X (will be named ANforNodeX) will have the same elevation as Node X  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adds the phrase \"AN1forNode\" to each node id as the id of the first artificial node (AN) added to each demand node\n",
    "anodeids=[\"ANforNode\"+str(id) for id in demand_nodes]\n",
    "# Sets the base demand for all added nodes as 0\n",
    "base_demands=[0]*len(anodeids)\n",
    "# No demand pattern is assigned to any demand node\n",
    "demand_patterns=[\"     \"]*len(anodeids)\n",
    "# Dataframe with all the required fields for AN1 [ID   Elevation   Demand   Pattern   ;]\n",
    "added_nodes=pd.DataFrame(list(zip(anodeids,elevations,base_demands,demand_patterns,semicolons)))\n",
    "# Exports the added junctions as a list of strings where each entry is a line of the junctions section\n",
    "added_nodes=added_nodes.to_string(header=False,index=False,col_space=10).splitlines()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing Added Pipes\n",
    "Similar to the reservoirs section, each field for the pipe entries is stored in a separate list  \n",
    "FCVRes method requires the addition of one pipe (Refer to the above figure)  \n",
    "The pipe should have a negligible major loss and thus will have a small length (0.1 m), a diameter of 350 mm, a HW coefficient of 130, and a minor loss coefficient of:  \n",
    "$$ K_{Minor}=(H^{des}-H^{min})\\frac{g\\pi^2D^4}{8Q_{des}^2}$$\n",
    "The diameter is unified at 0.35 m for simplicity (350 mm)  \n",
    "While the second pipe will have a minor loss coefficient of 0, and serves to connect the PSV to the downstream artificial reservoir  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adds the phrase PipeforNode to each node id and stores it as a pipe id\n",
    "pipeids=['Pipe1forNode'+str(id) for id in demand_nodes]\n",
    "# Calculates the minor loss coefficient of each pipe to simulate the head-flow relationship\n",
    "minorloss=[pressure_diff*9.81*np.pi**2*0.35**4/(8*demand**2) for demand in desired_demands]\n",
    "# Sets all lengths to 0.1 m\n",
    "lengths=[0.1]*len(pipeids)\n",
    "# Sets all diameters to 1 m (1000 mm)\n",
    "diameters_pipes=[350]*len(pipeids)\n",
    "# Sets all Hazen-Williams Coefficients as 130\n",
    "hazen=[130]*len(pipeids)\n",
    "# Sets all created pipes to work as Check Valved to prevent backflow\n",
    "status=['CV']*len(pipeids)\n",
    "# list of semicolons\n",
    "semicolons=[\";\"]*len(pipeids)\n",
    "# Assemble all lists into a dataframe where each row is the definition for one simple reservoir\n",
    "# Data frame with all required fields [ID   Node1   Node2   Length   Diameter   Roughness   MinorLoss   Status   ;]\n",
    "added_pipes=pd.DataFrame(list(zip(pipeids,anodeids,reservoirids,lengths,diameters_pipes,hazen,minorloss,status,semicolons)))\n",
    "# Exports the pipe section as a list of strings where each entry is a line of the pipes section\n",
    "added_pipes=added_pipes.to_string(header=False,index=False,col_space=10).splitlines()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing Valves Section\n",
    "For each original demand node, a Flow-Control Valve is added restrict the flow to the users desired flow rate $Q^{des}$  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adds the phrase APSVforNode to each node id and stores it as a PSV valve id\n",
    "valveids=[\"FCVforNode\"+str(id) for id in demand_nodes]\n",
    "# From nodes are the original demand nodes and to nodes are the artificial nodes\n",
    "# Sets all valve diameters to 12 (will not affect head loss across valve)\n",
    "valve_diameters=[12.0000]*len(valveids)\n",
    "# Sets the type of all valves to Flow-Control Valves\n",
    "valve_types=[\"FCV\"]*len(valveids)\n",
    "# Sets the valve setting for each valve to the base demand of the original demand nodes (converts back to LPS)\n",
    "valve_settings=[demand*1000 for demand in desired_demands]\n",
    "# Sets the minor loss coefficient across the valve to 0\n",
    "valve_minor_loss=[\"0.0000\"]*len(valveids)\n",
    "# Semicolons at the end of each line\n",
    "semicolons=[';']*len(valveids)\n",
    "# Data frame with all required fields [ID   Node1   Node2   Diameter   Type   Setting   MinorLoss   ;]\n",
    "added_valves=pd.DataFrame(list(zip(valveids,demand_nodes,anodeids,valve_diameters,valve_types,valve_settings,valve_minor_loss,semicolons)))\n",
    "added_valves=added_valves.to_string(header=False,index=False,col_space=10).splitlines()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing Reservoir & AN Coordinates  \n",
    "Each reservoir's coordinates are translated by XX m in both x and y directions  \n",
    "The ANs will be translated YY meters in both directions  \n",
    "These coordinates are merely for display and do not affect the simulation in any way  \n",
    "[SCALE THESE VALUES FOR BETTER DISPLAY BASED ON YOUR INPUT FILE SCALE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set preferred translation distance for [AN1,AN2,AT] where AN is Artificial Node and AT is the Artifical Tank\n",
    "x_direct_distance=[-30,-60]\n",
    "y_driect_distance=[30,0]\n",
    "# Translates the reservoirs by a 100 m in both axes \n",
    "anode_xcoord=[x+x_direct_distance[0] for x in xcoordinates]\n",
    "reservoir_xcoord =[x+x_direct_distance[1] for x in xcoordinates]\n",
    "anode_ycoord=[y+y_driect_distance[0] for y in ycoordinates]\n",
    "reservoir_ycoord =[y+y_driect_distance[1] for y in ycoordinates]\n",
    "\n",
    "added_xcoordinates=anode_xcoord+reservoir_xcoord\n",
    "added_ycoordinates=anode_ycoord+reservoir_ycoord\n",
    "ids_coords=anodeids+reservoirids\n",
    "\n",
    "# Assemble all lists into a dataframe where each row is the coordinates for one artificial reservoir or node\n",
    "added_coordinates=pd.DataFrame(list(zip(ids_coords,added_xcoordinates,added_ycoordinates)))\n",
    "# Exports the coordinate section as a list of strings where each entry is a line of the coordinates section\n",
    "added_coordinates=added_coordinates.to_string(header=False,index=False,col_space=10).splitlines()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rewriting Base Demands\n",
    "After creating the required additions to the original demand nodes, the base demands for all demand junctions has to be reset to zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of zero base demands for all nodes\n",
    "zerodemands=[0]*len(all_nodes)\n",
    "# White space indicating no patterns\n",
    "pattern=['     ']*len(all_nodes)\n",
    "semicolons=[';']*len(all_nodes)\n",
    "original_nodes=pd.DataFrame(list(zip(all_nodes,all_elevations,zerodemands,pattern,semicolons)))\n",
    "original_nodes=original_nodes.to_string(header=False,index=False,col_space=10).splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opens .inp file to read\n",
    "file=open(abs_path,'r')\n",
    "lines=[]            # list to store all lines in the .inp file\n",
    "linecount=0         # Counter for the number of lines\n",
    "junctions_marker=0  # To store the line number at which the junctions section starts\n",
    "reservoirs_marker=0 # To store the line number at which the reservoir section ends\n",
    "pipes_marker=0      # To store the line number at which the pumps section starts\n",
    "valves_marker=0     # to store the line number at which the valves section\n",
    "coords_marker=0     # To store the line number at which the vertices section starts\n",
    "\n",
    "# Loops over each line in the input file \n",
    "for line in file:\n",
    "    # Record the position of the phrase [JUNCTIONS] and add 2 to skip the header line\n",
    "    if re.search('\\[JUNCTIONS\\]',line):\n",
    "        junctions_marker=linecount+2\n",
    "    # Record the position of the phrase [TANKS] and subtract 1 for the end of the reservoirs section\n",
    "    if re.search('\\[TANKS\\]',line):\n",
    "        reservoirs_marker=linecount-1\n",
    "     # Record the position of the phrase [PUMPS] and subtract 1 to add pipes to the end of the pipe section\n",
    "    if re.search('\\[PUMPS\\]',line):\n",
    "        pipes_marker=linecount-1\n",
    "    # Record the position of the phrase [VALVES] and add 2 to skip the header line\n",
    "    if re.search('\\[VALVES\\]',line):\n",
    "        valves_marker=linecount+2\n",
    "     # Record the position of the phrase [Vertices] and subtract 1 to add Tank cooridnates to the end of the coordinates section\n",
    "    if re.search('\\[VERTICES\\]',line):\n",
    "        coords_marker=linecount-1\n",
    "    linecount+=1\n",
    "    # Store all lines in a list\n",
    "    lines.append(line)\n",
    "file.close()\n",
    "\n",
    "# Translate the reservoirs marker by the length of the added nodes (ANs) that will be added before it (as it will displace all subsequent lines)\n",
    "reservoirs_marker+=len(added_nodes)\n",
    "# Translate the pipes marker by the length of the reservoir section and the added nodesthat will be added before it (as it will displace all subsequent lines)\n",
    "pipes_marker+=len(added_reservoirs)+len(added_nodes)\n",
    "# Translate the coordinates marker by the length of the added reservoirs, pipes and nodes\n",
    "valves_marker+=len(added_reservoirs)+len(added_pipes)+len(added_nodes)\n",
    "# Translate the coordinates marker by the length of the added tanks, pipes, nodes and valves\n",
    "coords_marker+=len(added_reservoirs)+len(added_pipes)+len(added_valves)+len(added_nodes)\n",
    "\n",
    "# Inserts the created sections in their appropriate location in the list of lines\n",
    "lines[junctions_marker:junctions_marker+len(original_nodes)]=original_nodes\n",
    "lines[junctions_marker+len(original_nodes):junctions_marker+len(original_nodes)]=added_nodes\n",
    "lines[reservoirs_marker:reservoirs_marker]=added_reservoirs\n",
    "lines[pipes_marker:pipes_marker]=added_pipes\n",
    "lines[valves_marker:valves_marker]=added_valves\n",
    "lines[coords_marker:coords_marker]=added_coordinates\n",
    "\n",
    "# Opens a new file in the same directory to write the modified network .inp file in\n",
    "file=open(directory/pathlib.Path(name_only+'FCV-Res.inp'),'w')\n",
    "c=0     #line counter\n",
    "\n",
    "# All lines added by this script are missing a new line character at the end, the conditional statements below add the new line character for these lines only and writes all lines to the file\n",
    "for line in lines:\n",
    "    if c>=junctions_marker and c<=junctions_marker+len(original_nodes)+len(added_nodes):\n",
    "        file.write(line+'\\n')\n",
    "    elif c>=reservoirs_marker and c<=reservoirs_marker+len(added_reservoirs):\n",
    "        file.write(line+'\\n')\n",
    "    elif c>=pipes_marker and c<=pipes_marker+len(added_pipes):\n",
    "        file.write(line+'\\n')\n",
    "    elif c>=valves_marker and c<=valves_marker+len(added_valves):\n",
    "        file.write(line+'\\n')\n",
    "    elif c>=coords_marker and c<=coords_marker+len(added_coordinates):\n",
    "        file.write(line+'\\n')\n",
    "    else: file.write(line)    \n",
    "    c+=1\n",
    "file.close()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References:\n",
    "##### [1] N. B. Gorev and I. F. Kodzhespirova, “Noniterative Implementation of Pressure-Dependent Demands Using the Hydraulic Analysis Engine of EPANET 2,” Water Resources Management, vol. 27, no. 10, pp. 3623–3630, Aug. 2013, doi: 10.1007/s11269-013-0369-1."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
